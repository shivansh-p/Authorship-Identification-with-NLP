{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yang-su2000/Authorship-Identification-with-NLP/blob/main/1-conv1d_cpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# 1D Convolution on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5gwyPUUumRA"
      },
      "source": [
        "## 1. Set-up "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNyXaMjvumRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0084c6ae-ab41-486c-8868-d36e9482a39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fslOIHToumRB"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username    \n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfKvlI6fumRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c6e7a2-2e44-47fc-bc43-fb5bb025b33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/ece5545’: File exists\n",
            "/content/gdrive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-yang-su2000' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/ece5545/a3-yang-su2000\n",
            "M\t1-conv1d_cpu.ipynb\n",
            "M\t2-conv1d_gpu.ipynb\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 7 (delta 5), reused 7 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), 1.45 KiB | 0 bytes/s, done.\n",
            "From https://github.com/ML-HW-SYS/a3-yang-su2000\n",
            "   172b133..8c34443  main       -> origin/main\n",
            "Updating 172b133..8c34443\n",
            "Fast-forward\n",
            " src/ops.py               | 125 \u001b[32m+++++++++++++++++++++++++++++++\u001b[m\u001b[31m----------------\u001b[m\n",
            " tests/test_1dconv_cpu.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 84 insertions(+), 45 deletions(-)\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfYFWbSkumRC"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p1XcV5TumRE"
      },
      "source": [
        "Verify the following cell prints your github repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSCb_BXlumRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db6586b-4515-4b7d-d408-b6b67bea1382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-conv1d_cpu.ipynb   4-gemm_gpu.ipynb\t    README.md\t      tests\n",
            "2-conv1d_gpu.ipynb   5-conv2d_dw_gpu.ipynb  repo_profiler.py\n",
            "3-conv1d_fpga.ipynb  leaderboard_id.txt     src\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyx3vv_3umRF"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liD8WRKAFuut",
        "outputId": "9b95c9ee-b3e1-4569-c6dd-b25b2dff62c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 23.0.1 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01l1WUgRumRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683679c2-d1a8-4028-8e23-8d4723dcb7b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Collecting tlcpack-nightly-cu102\n",
            "  Downloading https://github.com/tlc-pack/tlcpack/releases/download/v0.12.dev/tlcpack_nightly_cu102-0.13.dev40%2Bg62f9b1d29-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.10.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (5.9.4)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (1.22.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (6.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (22.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from tlcpack-nightly-cu102) (2.2.1)\n",
            "Installing collected packages: tlcpack-nightly-cu102\n",
            "Successfully installed tlcpack-nightly-cu102-0.13.dev40+g62f9b1d29\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwbPgyceumRG"
      },
      "source": [
        "## 3. Implement `make_conv1d_cpu_scheduler_func` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
        "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then \n",
        "$$\n",
        "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
        "$$\n",
        "\n",
        "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
        "\n",
        "The `make_conv1d_cpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array. \n",
        "You should return both the TVM schedule and the TVM operator for \n",
        "1. Input $x$\n",
        "2. Input $y$\n",
        "3. Output $out$\n",
        "\n",
        "The schedule should be able to used to build a function with signature $func(x, y, out)$. \n",
        "Please see the following cells the usage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.formatters import BaseFormatter\n",
        "import os\n",
        "import tvm\n",
        "from tvm import te\n",
        "\n",
        "def make_conv1d_cpu_scheduler1(M, N, bn=32, kfactor=32):\n",
        "    # baseline\n",
        "    A = te.placeholder((M,), name=\"A\")\n",
        "    W = te.placeholder((N,), name=\"W\")\n",
        "    k = te.reduce_axis((0, M + N - 1), \"k\")\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),\n",
        "        lambda n: te.sum(tvm.tir.if_then_else(\n",
        "            tvm.tir.any(k < 0, k >= M, n - k < 0, n - k >= N),\n",
        "            tvm.tir.const(0.0, \"float32\"),\n",
        "            A[k] * W[n - k]), axis=k),\n",
        "        name=\"B\",\n",
        "    )\n",
        "    s = te.create_schedule(B.op)\n",
        "\n",
        "    # Allocate write cache\n",
        "    BB = s.cache_write(B, \"global\")\n",
        "\n",
        "    # Blocking by loop tiling\n",
        "    xo, xi = s[B].split(s[B].op.axis[0], factor=bn)\n",
        "\n",
        "    # Write cache is computed at xo\n",
        "    s[BB].compute_at(s[B], xi)\n",
        "\n",
        "    # New inner axes\n",
        "    (xc,) = s[BB].op.axis\n",
        "\n",
        "    # Blocking by loop tiling for reduction axis\n",
        "    (k,) = s[BB].op.reduce_axis\n",
        "    ko, ki = s[BB].split(k, factor=kfactor)\n",
        "\n",
        "    # Vectorization\n",
        "    # s[BB].reorder(ko, xc, ki)\n",
        "    # s[BB].unroll(ki)\n",
        "    # s[BB].vectorize(xc)\n",
        "\n",
        "    # Parallel\n",
        "    s[BB].parallel(xc)\n",
        "\n",
        "    # Parallel\n",
        "    s[B].parallel(xo)\n",
        "    \n",
        "    return s, A, W, B"
      ],
      "metadata": {
        "id": "lbXyQrjHIpXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "def make_conv1d_cpu_func(M, N):\n",
        "    s, A, W, O = make_conv1d_cpu_scheduler1(M, N)\n",
        "    func = tvm.build(s, [A, W, O], \"llvm\")\n",
        "    return func\n",
        "\n",
        "def test_speed_conv1d_cpu():\n",
        "    # Define dimension\n",
        "    dev = tvm.device('llvm', 0)\n",
        "    M = 1024\n",
        "    N = 1024\n",
        "    n_repeat = 100\n",
        "    func = make_conv1d_cpu_func(M, N)\n",
        "\n",
        "    def tvm_time():\n",
        "        # Create random test data\n",
        "        np.random.seed(seed=int(time.time()))\n",
        "        a_np = np.random.rand(M).astype(np.float32)\n",
        "        w_np = np.random.rand(N).astype(np.float32)\n",
        "\n",
        "        # Time the optimized implementation\n",
        "        a = tvm.nd.array(a_np, dev)\n",
        "        w = tvm.nd.array(w_np, dev)\n",
        "        b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "\n",
        "        func(a, w, b)\n",
        "\n",
        "    time_tvm = timeit.timeit(tvm_time, number=n_repeat)\n",
        "    return time_tvm\n",
        "\n",
        "test_speed_conv1d_cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaL6UYes1oGf",
        "outputId": "6c63b7a9-5f36-4cbc-bc95-51259478f4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33159597500002747"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYlQNGnWumRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e846298-a5f5-445f-a5d6-2152ce5488f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: [0.26200765 0.830693   1.2422107  ... 0.5778411  0.7431597  0.5678245 ]\n",
            "Output: [0.26200765 0.830693   1.2422107  ... 0.5778411  0.7431597  0.5678245 ]\n",
            "1D conv TVM runtime: 32.971833 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_conv1d_cpu_scheduler\n",
        "\n",
        "M = 4096\n",
        "N = 128\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M).astype(dtype)\n",
        "w_np = np.random.rand(N).astype(dtype)\n",
        "b_np = np.convolve(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_conv1d_cpu_scheduler(M, N)\n",
        "func = tvm.build(s, [A, W, B], \"llvm\")\n",
        "\n",
        "dev = tvm.cpu()\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M+N-1), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat=100)\n",
        "\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"1D conv TVM runtime: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwaNWdciumRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe860d2-c007-41b6-fb1e-f57a6f59c55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
            "        for n_outer in T.parallel(132):\n",
            "            B_global = T.allocate([1], \"float32\", \"global\")\n",
            "            for n_inner in range(32):\n",
            "                B_global_1 = T.Buffer((1,), data=B_global, align=4)\n",
            "                B_global_1[0] = T.float32(0)\n",
            "                if T.likely(n_outer * 32 + n_inner < 4223):\n",
            "                    for k_outer, k_inner in T.grid(132, 32):\n",
            "                        if T.likely(k_outer * 32 + k_inner < 4223):\n",
            "                            cse_var_2: T.int32 = k_outer * 32\n",
            "                            cse_var_1: T.int32 = n_outer * 32 + n_inner - k_inner - cse_var_2\n",
            "                            A_1 = T.Buffer((4096,), data=A.data)\n",
            "                            W_1 = T.Buffer((128,), data=W.data)\n",
            "                            B_global_1[0] = B_global_1[0] + T.if_then_else(128 <= k_outer or cse_var_1 < 0 or 128 <= cse_var_1, T.float32(0), A_1[cse_var_2 + k_inner] * W_1[cse_var_1])\n",
            "                if T.likely(n_outer * 32 + n_inner < 4223):\n",
            "                    B_1 = T.Buffer((4223,), data=B.data)\n",
            "                    B_1[n_outer * 32 + n_inner] = B_global_1[0]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ozhQY7gumRH",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bfbeea-e88e-4c61-9f30-62a4bf6ef77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-yang-su2000\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.9.16, pytest-7.2.2, pluggy-1.0.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-yang-su2000\n",
            "plugins: anyio-3.6.2\n",
            "collected 15 items                                                             \u001b[0m\n",
            "\n",
            "tests/test_1dconv_cpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                 [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 9.70s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_1dconv_cpu.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}